def download_data():
    # download the dataset if it doesn't exist already
    # save it to file_path
    pass

def clean_data():
    # load the dataset
    # drop rows with missing values
    # return numpy arrays for features and labels
    pass

def preprocess_data(features, labels):
    # accepts numpy arrays
    # encode categorical variables
    # scale numerical features
    # split the data into train/test features and labels
    # return numpy arrays for X_train, X_test, y_train, y_test
    pass

def train_model(X_train, y_train, X_test, y_test):
    # train a model and save it 
    pass

def predict_new_data(X_new):
    # load the model and make predictions
    # return a string of the predicted class
    pass

def run_training_pipeline():
    # load data
    # clean data
    # preprocess data
    # train model
    pass